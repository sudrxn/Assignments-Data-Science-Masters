{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d13d843e-8580-410a-bd12-aa767ac6b579",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. **Q1. What is the Filter method in feature selection, and how does it work?**\n",
    "    - The Filter method involves selecting features based on their correlation with the target variable. It calculates a statistical measure like chi-square or correlation coefficient between each feature and the target. Features with high correlation are selected. It's simple and efficient but doesn't consider feature interactions.\n",
    "```python\n",
    "# Example code for Filter method\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "selector = SelectKBest(score_func=chi2, k=3) # Select 3 best features\n",
    "X_new = selector.fit_transform(X, y) # X: input features, y: target variable\n",
    "```\n",
    "\n",
    "2. **Q2. How does the Wrapper method differ from the Filter method in feature selection?**\n",
    "    - The Wrapper method uses a machine learning model to evaluate feature quality, considering feature interactions. It's computationally expensive as it trains models for different feature subsets.\n",
    "```python\n",
    "# Example code for Wrapper method (e.g., Recursive Feature Elimination)\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "rfe = RFE(model, 3) # Select 3 best features\n",
    "fit = rfe.fit(X, y) # X: input features, y: target variable\n",
    "```\n",
    "\n",
    "3. **Q3. What are some common techniques used in Embedded feature selection methods?**\n",
    "    - Common Embedded methods include LASSO, Ridge Regression, and Decision Tree-based methods. These incorporate feature selection into model training, balancing performance and complexity.\n",
    "```python\n",
    "# Example code for LASSO (L1 regularization)\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X, y) # X: input features, y: target variable\n",
    "```\n",
    "\n",
    "4. **Q4. What are some drawbacks of using the Filter method for feature selection?**\n",
    "    - Drawbacks include its inability to capture feature interactions, reliance on individual feature relevance, and potential selection of redundant features.\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "5. **Q5. In which situations would you prefer using the Filter method over the Wrapper method for feature selection?**\n",
    "    - Use the Filter method for computational efficiency, especially with large datasets or when feature independence is assumed.\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "6. **Q6. In a telecom company, you are working on a project to develop a predictive model for customer churn. You are unsure of which features to include in the model because the dataset contains several different ones. Describe how you would choose the most pertinent attributes for the model using the Filter Method.**\n",
    "    - I would calculate correlations between each feature and churn. High-correlation features, like call duration or complaints, would be chosen. However, further analysis is needed to confirm predictive power.\n",
    "```python\n",
    "# Example code for correlation calculation\n",
    "correlation_matrix = df.corr()\n",
    "```\n",
    "\n",
    "7. **Q7. You are working on a project to predict the outcome of a soccer match. You have a large dataset with many features, including player statistics and team rankings. Explain how you would use the Embedded method to select the most relevant features for the model.**\n",
    "    - I'd use a Decision Tree or Random Forest to rank feature importance based on predicting match outcomes. These algorithms consider both individual feature importance and interactions.\n",
    "```python\n",
    "# Example code for Random Forest feature importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X, y) # X: input features, y: target variable\n",
    "importance = model.feature_importances_\n",
    "```\n",
    "\n",
    "8. **Q8. You are working on a project to predict the price of a house based on its features, such as size, location, and age. You have a limited number of features, and you want to ensure that you select the most important ones for the model. Explain how you would use the Wrapper method to select the best set of features for the predictor.**\n",
    "    - I'd use a Wrapper method like Recursive Feature Elimination with a linear regression model. This would iteratively remove less important features until the best set is found.\n",
    "```python\n",
    "# Example code for Recursive Feature Elimination with Linear Regression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "rfe = RFE(model, 3) # Select 3 best features\n",
    "fit = rfe.fit(X, y) # X: input features, y: target variable\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c3c80b-02d0-4489-8637-ca3fededcd9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
