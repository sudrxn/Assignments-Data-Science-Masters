{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc03280a-9867-4f05-b776-25859033cfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# ans 1:\n",
    "\n",
    "\n",
    "\n",
    "# Importing essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Reading data into a DataFrame from a CSV file\n",
    "df = pd.read_csv(\"encoded_data_benguluru1.csv\")\n",
    "\n",
    "# Splitting data into two parts\n",
    "X = df.drop(\"price\", axis=1)\n",
    "y = df[\"price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Standardize the values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Identify numeric columns\n",
    "numeric_columns = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Select only numeric columns for standardization\n",
    "X_train_numeric = X_train[numeric_columns]\n",
    "X_test_numeric = X_test[numeric_columns]\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_numeric_imputed = imputer.fit_transform(X_train_numeric)\n",
    "X_test_numeric_imputed = imputer.transform(X_test_numeric)\n",
    "\n",
    "# Standardize the numeric columns\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_numeric_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_numeric_imputed)\n",
    "\n",
    "\n",
    "# Starting regressor\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'kernel': ['linear', 'rbf', 'poly'], 'gamma': ['scale', 'auto']}\n",
    "\n",
    "# Create an SVR regressor\n",
    "sv_regressor = SVR()\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=sv_regressor, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Use the best model for prediction\n",
    "y_pred = best_model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c46c8929-bbe8-4de2-a525-14f96b1ffd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 55.10046664,  99.89961255,  55.10046664, ...,  55.10046664,\n",
       "        55.10046664, 149.90031332])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dafb6ae5-dcb6-4c6f-9b79-dfb7fe815961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-5.1.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.11.1)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.28.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.13)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Installing collected packages: filelock, gdown\n",
      "Successfully installed filelock-3.13.1 gdown-5.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Z9oLpmt6IDRNw7IeNcHYTGeJRYypRSC0\n",
      "To: /home/jovyan/work/encoded_data_benguluru1.csv\n",
      "100%|██████████| 938k/938k [00:00<00:00, 2.29MB/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown\n",
    "import gdown\n",
    "\n",
    "file_url = \"https://drive.google.com/uc?id=1Z9oLpmt6IDRNw7IeNcHYTGeJRYypRSC0\"\n",
    "output_file = \"encoded_data_benguluru1.csv\"\n",
    "\n",
    "gdown.download(file_url, output_file, quiet=False)\n",
    "df = pd.read_csv(output_file)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ba2f90-f5a2-40d6-8dd7-7fc7966f7487",
   "metadata": {},
   "source": [
    "## so the best parameters would be :\n",
    "## Best Parameters: {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef41847-2e9f-4058-8e35-cef761eb8d83",
   "metadata": {},
   "source": [
    "# ans 2:\n",
    "\n",
    "If your goal is to predict the actual price of a house as accurately as possible, Mean Squared Error (MSE) would be a more appropriate evaluation metric for an SVM regression model.\n",
    "\n",
    "Mean Squared Error (MSE) measures the average squared difference between the predicted values and the actual values. In the context of predicting house prices, MSE penalizes large errors more heavily than smaller errors. Minimizing MSE implies that you are trying to reduce the overall magnitude of prediction errors, which aligns well with the goal of accurate price prediction.\n",
    "\n",
    "On the other hand, R-squared (coefficient of determination) measures the proportion of the variance in the dependent variable that is predictable from the independent variables. While R-squared is a valuable metric for understanding the proportion of variance explained by the model, it may not directly convey how close your predictions are to the actual prices.\n",
    "\n",
    "In summary, for the specific goal of predicting house prices accurately, MSE is a more suitable metric as it directly reflects the accuracy of the predicted values in terms of their closeness to the actual prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5e4e7fe-1426-49ff-bd38-28e2410fdda2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096b7279-e688-4540-a777-28ab870669e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Assuming you have loaded your encoded data into X_train, X_test, y_train, y_test\n",
    "df = pd.read_csv(\"encoded_data_benguluru1.csv\")\n",
    "df_encoded=pd.get_dummies(df)\n",
    "df_encoded = df_encoded.dropna()\n",
    "X = df_encoded.drop(\"price\", axis=1)\n",
    "y = df_encoded[\"price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train an SVM regression model\n",
    "sv_regressor = SVR(kernel='linear', C=1.0)\n",
    "sv_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = sv_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate using Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "\n",
    "# Evaluate using R-squared\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f'R-squared: {r_squared}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56098c20-51b2-4001-9a1b-5e09a3ba7b46",
   "metadata": {},
   "source": [
    "# ans 3:\n",
    "\n",
    "When dealing with a dataset that has a significant number of outliers, Mean Squared Error (MSE) may not be the most appropriate regression metric. MSE is sensitive to outliers because it squares the differences between predicted and actual values, giving more weight to larger errors.\n",
    "\n",
    "A more robust metric in the presence of outliers is Mean Absolute Error (MAE). MAE is less affected by extreme values since it takes the absolute values of the differences between predicted and actual values. It is calculated as the average of the absolute differences between predictions and true values.\n",
    "\n",
    "Using MAE as a regression metric is often recommended when dealing with datasets containing outliers because it provides a more balanced measure of the model's accuracy without being heavily influenced by a few extreme observations.\n",
    "\n",
    "In scikit-learn, you can use `mean_absolute_error` from the `sklearn.metrics` module to calculate the Mean Absolute Error.\n",
    "\n",
    "Here's an example:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Assuming y_true and y_pred are your true and predicted values\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "```\n",
    "\n",
    "Consider using MAE when evaluating your SVM regression model on datasets with significant outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6887bb-cb74-418c-b321-139c97f458d7",
   "metadata": {},
   "source": [
    "# ans 4:\n",
    "\n",
    "When MSE (Mean Squared Error) and RMSE (Root Mean Squared Error) are very close, it is generally preferable to choose the RMSE as the evaluation metric, especially for regression tasks. The RMSE is essentially the square root of the MSE and shares the same unit as the target variable. Here's why RMSE is often preferred:\n",
    "\n",
    "1. **Interpretability:** The RMSE is more interpretable as it is in the same units as the target variable. This makes it easier to convey the magnitude of prediction errors in a way that aligns with the original scale of the data.\n",
    "\n",
    "2. **Sensitivity to Outliers:** The square root operation in RMSE mitigates the impact of large errors, making it less sensitive to outliers compared to MSE. If you have outliers in your data, RMSE provides a more balanced view of prediction errors.\n",
    "\n",
    "3. **Consistency with the Original Metric:** If your original goal or problem statement was framed in terms of RMSE or closely related metrics, it makes sense to stick with RMSE for consistency.\n",
    "\n",
    "While both metrics provide a measure of the average magnitude of prediction errors, RMSE is often preferred for its interpretability and robustness to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c0c12f-7fca-40be-a55e-a3fe0feceaba",
   "metadata": {},
   "source": [
    "# asn 5:\n",
    "\n",
    "If your goal is to measure how well the model explains the variance in the target variable, then R-squared (coefficient of determination) would be the most appropriate evaluation metric.\n",
    "\n",
    "R-squared provides a measure of the proportion of the variance in the dependent variable that is predictable from the independent variables. Specifically, it quantifies the goodness of fit of the model by comparing the variability of the predicted values to the variability of the actual values. The value of R-squared ranges from 0 to 1, where 1 indicates a perfect fit.\n",
    "\n",
    "For SVM regression models with different kernels (linear, polynomial, and RBF), you can use the `r2_score` function from scikit-learn to calculate R-squared. Here's an example:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming X, y are your features and target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train SVM regression models with different kernels\n",
    "kernels = ['linear', 'poly', 'rbf']\n",
    "for kernel in kernels:\n",
    "    sv_regressor = SVR(kernel=kernel)\n",
    "    sv_regressor.fit(X_train_scaled, y_train)\n",
    "    y_pred = sv_regressor.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate R-squared\n",
    "    r_squared = r2_score(y_test, y_pred)\n",
    "    print(f'R-squared for {kernel} kernel: {r_squared}')\n",
    "```\n",
    "\n",
    "This code demonstrates how to train SVM regression models with different kernels and evaluate their performance using R-squared. Adjust the kernel types and other parameters based on your specific scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c5cb4c-d80a-4632-ab22-402d07e52485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
